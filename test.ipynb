{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from utils import *\n",
    "\n",
    "# from data_preprocessing.ihdp import * \n",
    "# from data_preprocessing.lalonde import *\n",
    "# from data_preprocessing.lbidd import *\n",
    "# from data_preprocessing.synthetic import *\n",
    "# from data_preprocessing.twins import *\n",
    "\n",
    "k = 2\n",
    "# ci_estimators = ['sl', 'tl', 'xl', 'dml', 'orf', 'dr', 'sparse_dml', 'kernel_dml', 'CausalForestDML']\n",
    "\n",
    "\n",
    "def causal_inference_analysis(model_y, model_t, str_causal_model,x, y, t, true_ate, true_ate_std, true_ite):\n",
    "    causal_model = get_estimators(str_causal_model, model_y, model_t)\n",
    "\n",
    "    start_time = time.time()\n",
    "    causal_model.fit(y, t, X=x, W=None)\n",
    "    run_time = time.time() - start_time\n",
    "\n",
    "    estimated_ate = causal_model.ate(x)\n",
    "    \n",
    "    estimated_ite_values = causal_model.effect(x)\n",
    "\n",
    "    tao_risk, mu_risk = calculate_risks(true_ate, estimated_ate, true_ite, estimated_ite_values)\n",
    "\n",
    "    return {'est_ate': estimated_ate, 'mu_risk': mu_risk, 'tao_risk': tao_risk, \n",
    "            'true_ate_std': true_ate_std, 'run_time': run_time, \n",
    "            'model_t': model_t.__class__.__name__, 'model_y': model_y.__class__.__name__}, estimated_ite_values\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dml\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dml' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred while running LinearRegression()-LogisticRegression() estimator with dml method: 'tuple' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "# classifiers = [GradientBoostingClassifier(),\n",
    "#                RandomForestClassifier(),\n",
    "#                LogisticRegression(),\n",
    "#                LogisticRegressionCV(),\n",
    "#                MLPClassifier(),\n",
    "#                DecisionTreeClassifier()]\n",
    "\n",
    "classifiers = [LogisticRegression()]\n",
    "\n",
    "# regressors = [GradientBoostingRegressor(),\n",
    "#             RandomForestRegressor(),\n",
    "#             LinearRegression(),\n",
    "#             ElasticNet(),\n",
    "#             ElasticNetCV(),\n",
    "#             Lasso(),\n",
    "#             LassoLars(),\n",
    "#             OrthogonalMatchingPursuit(),\n",
    "#             Ridge(),\n",
    "#             MLPRegressor(),\n",
    "#             DecisionTreeRegressor()]\n",
    "\n",
    "regressors = [LinearRegression()]\n",
    "\n",
    "ci_estimators = ['dml']\n",
    "\n",
    "data_dict = {'ihdp':load_ihdp()}\n",
    "all_results = []\n",
    "for key in data_dict:\n",
    "    data, X, T, Y, true_ite, true_ATE, true_ATE_stderr, is_discrete = data_dict[key]\n",
    "    my_list = regressors\n",
    "    mt_list = classifiers if is_discrete else regressors\n",
    "    for str_causal_model in ci_estimators:\n",
    "        is_meta = False\n",
    "        if str_causal_model in ['sl', 'xl', 'tl']:\n",
    "                is_meta = True\n",
    "        for model_y  in my_list:\n",
    "            count = 0\n",
    "            for model_t in mt_list:\n",
    "                try:\n",
    "                    temp_results = causal_inference_analysis(model_y, model_t, str_causal_model, X, Y, T, true_ATE, true_ATE_stderr, true_ite)\n",
    "                    temp_results['data'] = key\n",
    "                    all_results.append(temp_results)\n",
    "                    results_df = pd.DataFrame(all_results)\n",
    "                    results_df.to_csv(f'results/{data}_no_params_baselines.csv')\n",
    "                    print(f\"Completed running model_y: {model_y}, model_t: {model_t}, str_causal_model: {str_causal_model}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error occurred while running {model_y}-{model_t} estimator with {str_causal_model} method: {str(e)}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "742    0\n",
       "743    1\n",
       "744    0\n",
       "745    0\n",
       "746    0\n",
       "Name: treatment, Length: 747, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<econml.dml.dml.LinearDML at 0x169097760>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dml = LinearDML(model_t=model_t, model_y=model_y)\n",
    "dml.fit(Y, T.astype(int), X=X, W=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LinearDML'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dml.__class__.__name__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "X was not None when fitting, so can't be none for score or effect",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dml\u001b[39m.\u001b[39;49mate()\n",
      "File \u001b[0;32m~/Documents/EconML-CS696DS/econml/_cate_estimator.py:913\u001b[0m, in \u001b[0;36mTreatmentExpansionMixin.ate\u001b[0;34m(self, X, T0, T1)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mate\u001b[39m(\u001b[39mself\u001b[39m, X\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, T0\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, T1\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m--> 913\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mate(X\u001b[39m=\u001b[39;49mX, T0\u001b[39m=\u001b[39;49mT0, T1\u001b[39m=\u001b[39;49mT1)\n",
      "File \u001b[0;32m~/Documents/EconML-CS696DS/econml/_cate_estimator.py:212\u001b[0m, in \u001b[0;36mBaseCateEstimator.ate\u001b[0;34m(self, X, T0, T1)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mate\u001b[39m(\u001b[39mself\u001b[39m, X\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, T0, T1):\n\u001b[1;32m    191\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[39m    Calculate the average treatment effect :math:`E_X[\\\\tau(X, T0, T1)]`.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39m        Note that when Y is a vector rather than a 2-dimensional array, the result will be a scalar\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meffect(X\u001b[39m=\u001b[39;49mX, T0\u001b[39m=\u001b[39;49mT0, T1\u001b[39m=\u001b[39;49mT1), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/EconML-CS696DS/econml/_cate_estimator.py:909\u001b[0m, in \u001b[0;36mTreatmentExpansionMixin.effect\u001b[0;34m(self, X, T0, T1)\u001b[0m\n\u001b[1;32m    907\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meffect\u001b[39m(\u001b[39mself\u001b[39m, X\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, T0\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, T1\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m    908\u001b[0m     \u001b[39m# NOTE: don't explicitly expand treatments here, because it's done in the super call\u001b[39;00m\n\u001b[0;32m--> 909\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49meffect(X, T0\u001b[39m=\u001b[39;49mT0, T1\u001b[39m=\u001b[39;49mT1)\n",
      "File \u001b[0;32m~/Documents/EconML-CS696DS/econml/_cate_estimator.py:597\u001b[0m, in \u001b[0;36mLinearCateEstimator.effect\u001b[0;34m(self, X, T0, T1)\u001b[0m\n\u001b[1;32m    594\u001b[0m X, T0, T1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_treatments(X, T0, T1)\n\u001b[1;32m    595\u001b[0m \u001b[39m# TODO: what if input is sparse? - there's no equivalent to einsum,\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \u001b[39m#       but tensordot can't be applied to this problem because we don't sum over m\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m eff \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconst_marginal_effect(X)\n\u001b[1;32m    598\u001b[0m \u001b[39m# if X is None then the shape of const_marginal_effect will be wrong because the number\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[39m# of rows of T was not taken into account\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/EconML-CS696DS/econml/_ortho_learner.py:815\u001b[0m, in \u001b[0;36m_OrthoLearner.const_marginal_effect\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconst_marginal_effect\u001b[39m(\u001b[39mself\u001b[39m, X\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    814\u001b[0m     X, \u001b[39m=\u001b[39m check_input_arrays(X)\n\u001b[0;32m--> 815\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_fitted_dims(X)\n\u001b[1;32m    816\u001b[0m     \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    817\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ortho_learner_model_final\u001b[39m.\u001b[39mpredict()\n",
      "File \u001b[0;32m~/Documents/EconML-CS696DS/econml/_ortho_learner.py:507\u001b[0m, in \u001b[0;36m_OrthoLearner._check_fitted_dims\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_fitted_dims\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    506\u001b[0m     \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 507\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_d_x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mX was not None when fitting, so can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be none for score or effect\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    509\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_d_x \u001b[39m==\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:], \u001b[39m\"\u001b[39m\u001b[39mDimension mis-match of X with fitted X\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: X was not None when fitting, so can't be none for score or effect"
     ]
    }
   ],
   "source": [
    "dml.ate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<econml.dml.dml.LinearDML at 0x1405468e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dml = get_estimators(str_causal_model, model_y, model_t)\n",
    "dml = LinearDML(model_t=DecisionTreeClassifier(), model_y=ElasticNet())\n",
    "dml.fit(Y, T.astype(int), X=X, W=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "742    False\n",
       "743     True\n",
       "744    False\n",
       "745    False\n",
       "746    False\n",
       "Name: treatment, Length: 747, dtype: bool"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.orf import DMLOrthoForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#The covariates data has 46 features\n",
    "x = pd.read_csv(\"https://raw.githubusercontent.com/AMLab-Amsterdam/CEVAE/master/datasets/TWINS/twin_pairs_X_3years_samesex.csv\")\n",
    "\n",
    "#The outcome data contains mortality of the lighter and heavier twin\n",
    "y = pd.read_csv(\"https://raw.githubusercontent.com/AMLab-Amsterdam/CEVAE/master/datasets/TWINS/twin_pairs_Y_3years_samesex.csv\")\n",
    "\n",
    "#The treatment data contains weight in grams of both the twins\n",
    "t = pd.read_csv(\"https://raw.githubusercontent.com/AMLab-Amsterdam/CEVAE/master/datasets/TWINS/twin_pairs_T_3years_samesex.csv\")\n",
    "\n",
    "lighter_columns = ['pldel', 'birattnd', 'brstate', 'stoccfipb', 'mager8',\n",
    "       'ormoth', 'mrace', 'meduc6', 'dmar', 'mplbir', 'mpre5', 'adequacy',\n",
    "       'orfath', 'frace', 'birmon', 'gestat10', 'csex', 'anemia', 'cardiac',\n",
    "       'lung', 'diabetes', 'herpes', 'hydra', 'hemo', 'chyper', 'phyper',\n",
    "       'eclamp', 'incervix', 'pre4000', 'preterm', 'renal', 'rh', 'uterine',\n",
    "       'othermr', 'tobacco', 'alcohol', 'cigar6', 'drink5', 'crace',\n",
    "       'data_year', 'nprevistq', 'dfageq', 'feduc6', 'infant_id_0',\n",
    "       'dlivord_min', 'dtotord_min', 'bord_0',\n",
    "       'brstate_reg', 'stoccfipb_reg', 'mplbir_reg']\n",
    "heavier_columns = [ 'pldel', 'birattnd', 'brstate', 'stoccfipb', 'mager8',\n",
    "       'ormoth', 'mrace', 'meduc6', 'dmar', 'mplbir', 'mpre5', 'adequacy',\n",
    "       'orfath', 'frace', 'birmon', 'gestat10', 'csex', 'anemia', 'cardiac',\n",
    "       'lung', 'diabetes', 'herpes', 'hydra', 'hemo', 'chyper', 'phyper',\n",
    "       'eclamp', 'incervix', 'pre4000', 'preterm', 'renal', 'rh', 'uterine',\n",
    "       'othermr', 'tobacco', 'alcohol', 'cigar6', 'drink5', 'crace',\n",
    "       'data_year', 'nprevistq', 'dfageq', 'feduc6',\n",
    "       'infant_id_1', 'dlivord_min', 'dtotord_min', 'bord_1',\n",
    "       'brstate_reg', 'stoccfipb_reg', 'mplbir_reg']\n",
    "\n",
    "#Since data has pair property,processing the data to get separate row for each twin so that each child can be treated as an instance\n",
    "data = []\n",
    "\n",
    "for i in range(len(t.values)):\n",
    "    \n",
    "    #select only if both <=2kg\n",
    "    if t.iloc[i].values[1]>=2000 or t.iloc[i].values[2]>=2000:\n",
    "        continue\n",
    "    \n",
    "    this_instance_lighter = list(x.iloc[i][lighter_columns].values)\n",
    "    this_instance_heavier = list(x.iloc[i][heavier_columns].values)\n",
    "    \n",
    "    #adding weight\n",
    "    this_instance_lighter.append(t.iloc[i].values[1])\n",
    "    this_instance_heavier.append(t.iloc[i].values[2])\n",
    "    \n",
    "    #adding treatment, is_heavier\n",
    "    this_instance_lighter.append(0)\n",
    "    this_instance_heavier.append(1)\n",
    "    \n",
    "    #adding the outcome\n",
    "    this_instance_lighter.append(y.iloc[i].values[1])\n",
    "    this_instance_heavier.append(y.iloc[i].values[2])\n",
    "    data.append(this_instance_lighter)\n",
    "    data.append(this_instance_heavier)\n",
    "cols = [ 'pldel', 'birattnd', 'brstate', 'stoccfipb', 'mager8',\n",
    "       'ormoth', 'mrace', 'meduc6', 'dmar', 'mplbir', 'mpre5', 'adequacy',\n",
    "       'orfath', 'frace', 'birmon', 'gestat10', 'csex', 'anemia', 'cardiac',\n",
    "       'lung', 'diabetes', 'herpes', 'hydra', 'hemo', 'chyper', 'phyper',\n",
    "       'eclamp', 'incervix', 'pre4000', 'preterm', 'renal', 'rh', 'uterine',\n",
    "       'othermr', 'tobacco', 'alcohol', 'cigar6', 'drink5', 'crace',\n",
    "       'data_year', 'nprevistq', 'dfageq', 'feduc6',\n",
    "       'infant_id', 'dlivord_min', 'dtotord_min', 'bord',\n",
    "       'brstate_reg', 'stoccfipb_reg', 'mplbir_reg','wt','treatment','outcome']\n",
    "df = pd.DataFrame(columns=cols,data=data)\n",
    "df = df.astype({\"treatment\":'bool'}, copy=False) #explicitly assigning treatment column as boolean \n",
    "\n",
    "df.fillna(value=df.mean(),inplace=True)    #filling the missing values\n",
    "df.fillna(value=df.mode().loc[0],inplace=True)\n",
    "\n",
    "data_1 = df[df[\"treatment\"]==1]\n",
    "data_0 = df[df[\"treatment\"]==0]\n",
    "\n",
    "ITE = data_1[\"outcome\"] - data_0[\"outcome\"]\n",
    "ATE =  np.mean(ITE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    11984\n",
       "True     11984\n",
       "Name: treatment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.treatment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../datasets/IHDP/ihdp_splits_10iters_10folds.npz', allow_pickle=True)\n",
    "# n_iters = options.iters if options.iters > 0 else splits.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from sklearn.linear_model import (Lasso, LassoCV, ElasticNetCV, LogisticRegression,\n",
    "                                  LogisticRegressionCV,LinearRegression,\n",
    "                                  MultiTaskElasticNet,MultiTaskElasticNetCV)\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor,RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "models_and_parameters = [    ('elastic', ElasticNetCV(), {}),    \n",
    "('forest', RandomForestRegressor(),        {'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20],\n",
    "        'min_samples_leaf': [0.01, 0.02, 0.03, 0.04, 0.05, 1, 2, 3, 4, 5, 6, 7, 8, 9]}),\n",
    "    ('gbf', GradientBoostingRegressor(),\n",
    "        {\"n_estimators\": [100, 300, 500, 700, 1000],\n",
    "        \"max_depth\": [2, 4, 6, 8, 10],\n",
    "        \"min_samples_split\": [5, 10, 15, 20],\n",
    "        \"learning_rate\": [0.001, 0.01, 0.1, 0.2, 1]}),\n",
    "    ('nnet', MLPRegressor(),\n",
    "        {'hidden_layer_sizes': [4, 8, 16, 32, 64, 128],\n",
    "        'learning_rate_init': [0.0001, 0.001],\n",
    "        'batch_size': [32, 64, 128, 250]})\n",
    "]\n",
    "models_dict = {name: (model, params) for name, model, params in models_and_parameters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {name: {'model': model, 'parameters': params} for name, model, params in models_and_parameters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elastic': {'model': ElasticNetCV(), 'parameters': {}},\n",
       " 'forest': {'model': RandomForestRegressor(),\n",
       "  'parameters': {'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20],\n",
       "   'min_samples_leaf': [0.01,\n",
       "    0.02,\n",
       "    0.03,\n",
       "    0.04,\n",
       "    0.05,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9]}},\n",
       " 'gbf': {'model': GradientBoostingRegressor(),\n",
       "  'parameters': {'n_estimators': [100, 300, 500, 700, 1000],\n",
       "   'max_depth': [2, 4, 6, 8, 10],\n",
       "   'min_samples_split': [5, 10, 15, 20],\n",
       "   'learning_rate': [0.001, 0.01, 0.1, 0.2, 1]}},\n",
       " 'nnet': {'model': MLPRegressor(),\n",
       "  'parameters': {'hidden_layer_sizes': [4, 8, 16, 32, 64, 128],\n",
       "   'learning_rate_init': [0.0001, 0.001],\n",
       "   'batch_size': [32, 64, 128, 250]}}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
