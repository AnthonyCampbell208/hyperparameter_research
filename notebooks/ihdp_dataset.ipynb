{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.dml import LinearDML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from sklearn.linear_model import (Lasso, LassoCV, ElasticNetCV, LogisticRegression,\n",
    "                                  LogisticRegressionCV,LinearRegression,\n",
    "                                  MultiTaskElasticNet,MultiTaskElasticNetCV)\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor,RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from model_selection import SearchEstimatorList\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1', '5.59991628549083', '4.31877968420119', '3.26825638455712',\n",
      "       '6.8544566863328', '-0.528602821749802', '-0.343454502314042',\n",
      "       '1.12855393123738', '0.161702527138546', '-0.316603181521744',\n",
      "       '1.29521593563369', '1.1', '0', '1.2', '0.1', '0.2', '0.3', '0.4',\n",
      "       '1.3', '0.5', '1.4', '1.5', '1.6', '1.7', '0.6', '0.7', '0.8', '0.9',\n",
      "       '0.10', '0.11'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>5.59991628549083</th>\n",
       "      <th>4.31877968420119</th>\n",
       "      <th>3.26825638455712</th>\n",
       "      <th>6.8544566863328</th>\n",
       "      <th>-0.528602821749802</th>\n",
       "      <th>-0.343454502314042</th>\n",
       "      <th>1.12855393123738</th>\n",
       "      <th>0.161702527138546</th>\n",
       "      <th>-0.316603181521744</th>\n",
       "      <th>...</th>\n",
       "      <th>1.4</th>\n",
       "      <th>1.5</th>\n",
       "      <th>1.6</th>\n",
       "      <th>1.7</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>0.10</th>\n",
       "      <th>0.11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6.875856</td>\n",
       "      <td>7.856495</td>\n",
       "      <td>6.636059</td>\n",
       "      <td>7.562718</td>\n",
       "      <td>-1.736945</td>\n",
       "      <td>-1.802002</td>\n",
       "      <td>0.383828</td>\n",
       "      <td>2.244320</td>\n",
       "      <td>-0.629189</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.996273</td>\n",
       "      <td>6.633952</td>\n",
       "      <td>1.570536</td>\n",
       "      <td>6.121617</td>\n",
       "      <td>-0.807451</td>\n",
       "      <td>-0.202946</td>\n",
       "      <td>-0.360898</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>0.808706</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.366206</td>\n",
       "      <td>5.697239</td>\n",
       "      <td>1.244738</td>\n",
       "      <td>5.889125</td>\n",
       "      <td>0.390083</td>\n",
       "      <td>0.596582</td>\n",
       "      <td>-1.850350</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>-0.004017</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.963538</td>\n",
       "      <td>6.202582</td>\n",
       "      <td>1.685048</td>\n",
       "      <td>6.191994</td>\n",
       "      <td>-1.045229</td>\n",
       "      <td>-0.602710</td>\n",
       "      <td>0.011465</td>\n",
       "      <td>0.161703</td>\n",
       "      <td>0.683672</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4.762090</td>\n",
       "      <td>8.264795</td>\n",
       "      <td>4.707898</td>\n",
       "      <td>7.219442</td>\n",
       "      <td>0.467901</td>\n",
       "      <td>-0.202946</td>\n",
       "      <td>-0.733261</td>\n",
       "      <td>0.161703</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  5.59991628549083  4.31877968420119  3.26825638455712  6.8544566863328  \\\n",
       "0  0          6.875856          7.856495          6.636059         7.562718   \n",
       "1  0          2.996273          6.633952          1.570536         6.121617   \n",
       "2  0          1.366206          5.697239          1.244738         5.889125   \n",
       "3  0          1.963538          6.202582          1.685048         6.191994   \n",
       "4  0          4.762090          8.264795          4.707898         7.219442   \n",
       "\n",
       "   -0.528602821749802  -0.343454502314042  1.12855393123738  \\\n",
       "0           -1.736945           -1.802002          0.383828   \n",
       "1           -0.807451           -0.202946         -0.360898   \n",
       "2            0.390083            0.596582         -1.850350   \n",
       "3           -1.045229           -0.602710          0.011465   \n",
       "4            0.467901           -0.202946         -0.733261   \n",
       "\n",
       "   0.161702527138546  -0.316603181521744  ...  1.4  1.5  1.6  1.7  0.6  0.7  \\\n",
       "0           2.244320           -0.629189  ...    1    1    1    1    0    0   \n",
       "1          -0.879606            0.808706  ...    1    0    1    1    0    0   \n",
       "2          -0.879606           -0.004017  ...    1    0    1    1    0    0   \n",
       "3           0.161703            0.683672  ...    1    1    1    1    0    0   \n",
       "4           0.161703            0.058500  ...    1    1    1    1    0    0   \n",
       "\n",
       "   0.8  0.9  0.10  0.11  \n",
       "0    0    0     0     0  \n",
       "1    0    0     0     0  \n",
       "2    0    0     0     0  \n",
       "3    0    0     0     0  \n",
       "4    0    0     0     0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/AMLab-Amsterdam/CEVAE/master/datasets/IHDP/csv/ihdp_npci_1.csv\"\n",
    "ihdp_df = pd.read_csv(url)\n",
    "print(ihdp_df.columns)\n",
    "ihdp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treatment</th>\n",
       "      <th>y_factual</th>\n",
       "      <th>y_cfactual</th>\n",
       "      <th>mu0</th>\n",
       "      <th>mu1</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>...</th>\n",
       "      <th>x16</th>\n",
       "      <th>x17</th>\n",
       "      <th>x18</th>\n",
       "      <th>x19</th>\n",
       "      <th>x20</th>\n",
       "      <th>x21</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "      <th>x25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>6.875856</td>\n",
       "      <td>7.856495</td>\n",
       "      <td>6.636059</td>\n",
       "      <td>7.562718</td>\n",
       "      <td>-1.736945</td>\n",
       "      <td>-1.802002</td>\n",
       "      <td>0.383828</td>\n",
       "      <td>2.244320</td>\n",
       "      <td>-0.629189</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>2.996273</td>\n",
       "      <td>6.633952</td>\n",
       "      <td>1.570536</td>\n",
       "      <td>6.121617</td>\n",
       "      <td>-0.807451</td>\n",
       "      <td>-0.202946</td>\n",
       "      <td>-0.360898</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>0.808706</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>1.366206</td>\n",
       "      <td>5.697239</td>\n",
       "      <td>1.244738</td>\n",
       "      <td>5.889125</td>\n",
       "      <td>0.390083</td>\n",
       "      <td>0.596582</td>\n",
       "      <td>-1.850350</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>-0.004017</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>1.963538</td>\n",
       "      <td>6.202582</td>\n",
       "      <td>1.685048</td>\n",
       "      <td>6.191994</td>\n",
       "      <td>-1.045229</td>\n",
       "      <td>-0.602710</td>\n",
       "      <td>0.011465</td>\n",
       "      <td>0.161703</td>\n",
       "      <td>0.683672</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>4.762090</td>\n",
       "      <td>8.264795</td>\n",
       "      <td>4.707898</td>\n",
       "      <td>7.219442</td>\n",
       "      <td>0.467901</td>\n",
       "      <td>-0.202946</td>\n",
       "      <td>-0.733261</td>\n",
       "      <td>0.161703</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   treatment  y_factual  y_cfactual       mu0       mu1        x1        x2  \\\n",
       "0      False   6.875856    7.856495  6.636059  7.562718 -1.736945 -1.802002   \n",
       "1      False   2.996273    6.633952  1.570536  6.121617 -0.807451 -0.202946   \n",
       "2      False   1.366206    5.697239  1.244738  5.889125  0.390083  0.596582   \n",
       "3      False   1.963538    6.202582  1.685048  6.191994 -1.045229 -0.602710   \n",
       "4      False   4.762090    8.264795  4.707898  7.219442  0.467901 -0.202946   \n",
       "\n",
       "         x3        x4        x5  ...  x16  x17  x18  x19  x20  x21  x22  x23  \\\n",
       "0  0.383828  2.244320 -0.629189  ...    1    1    1    1    0    0    0    0   \n",
       "1 -0.360898 -0.879606  0.808706  ...    1    0    1    1    0    0    0    0   \n",
       "2 -1.850350 -0.879606 -0.004017  ...    1    0    1    1    0    0    0    0   \n",
       "3  0.011465  0.161703  0.683672  ...    1    1    1    1    0    0    0    0   \n",
       "4 -0.733261  0.161703  0.058500  ...    1    1    1    1    0    0    0    0   \n",
       "\n",
       "   x24  x25  \n",
       "0    0    0  \n",
       "1    0    0  \n",
       "2    0    0  \n",
       "3    0    0  \n",
       "4    0    0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col =  [\"treatment\", \"y_factual\", \"y_cfactual\", \"mu0\", \"mu1\",\"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\", \"x9\", \"x10\", \"x11\", \"x12\", \"x13\", \"x14\", \"x15\", \"x16\", \"x17\", \"x18\", \"x19\", \"x20\", \"x21\", \"x22\", \"x23\", \"x24\", \"x25\"]\n",
    "ihdp_df.columns = col\n",
    "ihdp_df = ihdp_df.astype({\"treatment\":'bool'}, copy=False)\n",
    "ihdp_df.head()\n",
    "# print(type(ihdp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "treatment     0\n",
       "y_factual     0\n",
       "y_cfactual    0\n",
       "mu0           0\n",
       "mu1           0\n",
       "x1            0\n",
       "x2            0\n",
       "x3            0\n",
       "x4            0\n",
       "x5            0\n",
       "x6            0\n",
       "x7            0\n",
       "x8            0\n",
       "x9            0\n",
       "x10           0\n",
       "x11           0\n",
       "x12           0\n",
       "x13           0\n",
       "x14           0\n",
       "x15           0\n",
       "x16           0\n",
       "x17           0\n",
       "x18           0\n",
       "x19           0\n",
       "x20           0\n",
       "x21           0\n",
       "x22           0\n",
       "x23           0\n",
       "x24           0\n",
       "x25           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for null values\n",
    "ihdp_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# ihdp_df_normalized = pd.DataFrame(scaler.fit_transform(ihdp_df), columns=ihdp_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 categorical variables\n",
      "\n",
      "The categorical variables are : []\n"
     ]
    }
   ],
   "source": [
    "#Explore Categorical variables\n",
    "categorical = [var for var in ihdp_df.columns if ihdp_df[var].dtype == 'O']\n",
    "\n",
    "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
    "\n",
    "print('The categorical variables are :', categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 30 numerical variables\n",
      "\n",
      "The numerical variables are : ['treatment', 'y_factual', 'y_cfactual', 'mu0', 'mu1', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20', 'x21', 'x22', 'x23', 'x24', 'x25']\n"
     ]
    }
   ],
   "source": [
    "#Explore numerical variables\n",
    "numerical = [var for var in ihdp_df.columns if ihdp_df[var].dtype!='O']\n",
    "\n",
    "print('There are {} numerical variables\\n'.format(len(numerical)))\n",
    "\n",
    "print('The numerical variables are :', numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign the Treatment, Features and Outcome variables with their respective columns\n",
    "#Column y_cfactual gives the outcome that would have been observed if treatment was not given.\n",
    "T = ihdp_df['treatment']\n",
    "feature_cols = [\"mu0\", \"mu1\", \"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\", \"x9\", \"x10\", \"x11\", \"x12\", \"x13\", \"x14\", \"x15\", \"x16\", \"x17\", \"x18\", \"x19\", \"x20\", \"x21\", \"x22\", \"x23\", \"x24\", \"x25\"]\n",
    "X = ihdp_df[feature_cols]\n",
    "\n",
    "#Column y_factual gives the observed Bayley Mental Development Index score\n",
    "Y = ihdp_df['y_factual']\n",
    "\n",
    "# X_train, X_test = train_test_split(X, test_size=0.2)\n",
    "Y_train, Y_test, T_train, T_test, X_train, X_test = train_test_split(Y, T, X, test_size=0.2)\n",
    "\n",
    "# X_train_ = np.concatenate((X_train, T_train.reshape(-1, 1)), axis=1)\n",
    "# X_test_ = np.concatenate((X_test, T_test.reshape(-1, 1)), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "Co-variance matrix is underdetermined. Inference will be invalid!\n"
     ]
    }
   ],
   "source": [
    "est = LinearDML(model_y='auto', model_t='auto', discrete_treatment=True, linear_first_stages=False, random_state=42)\n",
    "est.fit(Y_train, T_train, X=X_train, W=None)\n",
    "te_pred = est.effect(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m model_y \u001b[39m=\u001b[39m RandomForestRegressor()\n\u001b[0;32m      6\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(model_y, param_grid\u001b[39m=\u001b[39mparams, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train, Y_train)\n\u001b[0;32m      8\u001b[0m best_params_y \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_params_\n\u001b[0;32m      9\u001b[0m best_model_y \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32mc:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\concurrent\\futures\\_base.py:434\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    432\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 434\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    436\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    437\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20],\n",
    "    'min_samples_leaf': [0.01, 0.02, 0.03, 0.04, 0.05, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "}\n",
    "model_y = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(model_y, param_grid=params, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "best_params_y = grid_search.best_params_\n",
    "best_model_y = grid_search.best_estimator_\n",
    "print(best_model_y)\n",
    "\n",
    "model_t = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(model_t, param_grid=params, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, T_train)\n",
    "best_params_t = grid_search.best_params_\n",
    "best_model_t = grid_search.best_estimator_\n",
    "print(best_model_t)\n",
    "\n",
    "est1 = LinearDML(model_y=best_model_y, model_t=best_model_t, discrete_treatment=True, linear_first_stages=False, random_state=42)\n",
    "est1.fit(Y_train, T_train, X=X_train, W=None)\n",
    "te_pred1 = est1.effect(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "70 fits failed out of a total of 80.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1760, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'Cs' parameter of LogisticRegressionCV must be an int in the range [1, inf) or an array-like. Got 1000.0 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1760, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'Cs' parameter of LogisticRegressionCV must be an int in the range [1, inf) or an array-like. Got 100.0 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1760, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'Cs' parameter of LogisticRegressionCV must be an int in the range [1, inf) or an array-like. Got 10.0 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1760, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'Cs' parameter of LogisticRegressionCV must be an int in the range [1, inf) or an array-like. Got 2.0 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1760, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'Cs' parameter of LogisticRegressionCV must be an int in the range [1, inf) or an array-like. Got 0.5 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1760, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'Cs' parameter of LogisticRegressionCV must be an int in the range [1, inf) or an array-like. Got 0.1 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1760, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\shrut\\OneDrive\\Desktop\\EconML-CS696DS\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'Cs' parameter of LogisticRegressionCV must be an int in the range [1, inf) or an array-like. Got 0.05 instead.\n",
      "\n",
      "One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.81711485 0.81711485        nan        nan\n",
      "        nan        nan        nan        nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegressionCV(Cs=1, max_iter=1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "Co-variance matrix is underdetermined. Inference will be invalid!\n"
     ]
    }
   ],
   "source": [
    "# params = {\n",
    "#     # 'alphas' : np.logspace(np.log10(0.001), np.log10(20), num=8),\n",
    "#     # 'alphas': [0.001, 0.01, 0.1, 0.5, 1, 2, 10, 20]\n",
    "#     # 'max_iter': [1000, 10000]\n",
    "#     'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "#     'alphas': np.logspace(-4, 2, 20)\n",
    "# }\n",
    "alphas = [0.001, 0.01, 0.1, 0.5, 1, 2, 10, 20]\n",
    "\n",
    "params1 = {\n",
    "    'Cs': [1/0.001, 1/0.01, 1/0.1, 1/0.5, 1, 1/2, 1/10, 1/20],\n",
    "    'max_iter': [1000, 10000]\n",
    "}\n",
    "best_model_y = ElasticNetCV(alphas=alphas)\n",
    "# grid_search = GridSearchCV(model_y, param_grid=params, cv=5)\n",
    "# grid_search.fit(X_train, Y_train)\n",
    "# best_params_y = grid_search.best_params_\n",
    "# best_model_y = grid_search.best_estimator_\n",
    "# print(best_model_y)\n",
    "\n",
    "model_t = LogisticRegressionCV()\n",
    "grid_search = GridSearchCV(model_t, param_grid=params1, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, T_train)\n",
    "best_params_t = grid_search.best_params_\n",
    "best_model_t = grid_search.best_estimator_\n",
    "print(best_model_t)\n",
    "\n",
    "est2 = LinearDML(model_y=best_model_y, model_t=best_model_t, discrete_treatment=True, linear_first_stages=False, random_state=42)\n",
    "est2.fit(Y_train, T_train, X=X_train, W=None)\n",
    "te_pred2 = est2.effect(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(learning_rate=0.01, max_depth=2, min_samples_split=5,\n",
      "                          n_estimators=700)\n",
      "GradientBoostingClassifier(learning_rate=0.001, max_depth=2,\n",
      "                           min_samples_split=5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "Co-variance matrix is underdetermined. Inference will be invalid!\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"n_estimators\": [100, 300, 500, 700, 1000],\n",
    "    \"max_depth\": [2, 4, 6, 8, 10],\n",
    "    \"min_samples_split\": [5, 10, 15, 20],\n",
    "    \"learning_rate\": [0.001, 0.01, 0.1, 0.2, 1]\n",
    "}\n",
    "model_y = GradientBoostingRegressor()\n",
    "grid_search = GridSearchCV(model_y, param_grid=params, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "best_params_y = grid_search.best_params_\n",
    "best_model_y = grid_search.best_estimator_\n",
    "print(best_model_y)\n",
    "\n",
    "model_t = GradientBoostingClassifier()\n",
    "grid_search = GridSearchCV(model_t, param_grid=params, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, T_train)\n",
    "best_params_t = grid_search.best_params_\n",
    "best_model_t = grid_search.best_estimator_\n",
    "print(best_model_t)\n",
    "\n",
    "est3 = LinearDML(model_y=best_model_y, model_t=best_model_t, discrete_treatment=True, linear_first_stages=False, random_state=42)\n",
    "est3.fit(Y_train, T_train, X=X_train, W=None)\n",
    "te_pred3 = est3.effect(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(batch_size=64, hidden_layer_sizes=64, learning_rate_init=0.0001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "`sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(batch_size=32, hidden_layer_sizes=32, learning_rate_init=0.0001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "Co-variance matrix is underdetermined. Inference will be invalid!\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    # 'hidden_layers': [1, 2],\n",
    "    'hidden_layer_sizes': [4, 8, 16, 32, 64, 128],\n",
    "    'learning_rate_init': [0.0001, 0.001],\n",
    "    'batch_size': [32, 64, 128, 250]\n",
    "}\n",
    "model_y = MLPRegressor()\n",
    "grid_search = GridSearchCV(model_y, param_grid=params, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "best_params_y = grid_search.best_params_\n",
    "best_model_y = grid_search.best_estimator_\n",
    "print(best_model_y)\n",
    "\n",
    "model_t = MLPClassifier()\n",
    "grid_search = GridSearchCV(model_t, param_grid=params, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, T_train)\n",
    "best_params_t = grid_search.best_params_\n",
    "best_model_t = grid_search.best_estimator_\n",
    "print(best_model_t)\n",
    "\n",
    "est4 = LinearDML(model_y=best_model_y, model_t=best_model_t, discrete_treatment=True, linear_first_stages=False, random_state=42)\n",
    "est4.fit(Y_train, T_train, X=X_train, W=None)\n",
    "te_pred4 = est4.effect(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # 'hidden_layers': [1, 2],\n",
    "    'hidden_layer_sizes': [4, 8, 16, 32, 64, 128],\n",
    "    'learning_rate_init': [0.0001, 0.001],\n",
    "    'batch_size': [32, 64, 128, 250]\n",
    "}\n",
    "model_y = MLPRegressor()\n",
    "grid_search = GridSearchCV(model_y, param_grid=params, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "best_params_y = grid_search.best_params_\n",
    "best_model_y = grid_search.best_estimator_\n",
    "print(best_model_y)\n",
    "\n",
    "model_t = MLPClassifier()\n",
    "grid_search = GridSearchCV(model_t, param_grid=params, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, T_train)\n",
    "best_params_t = grid_search.best_params_\n",
    "best_model_t = grid_search.best_estimator_\n",
    "print(best_model_t)\n",
    "\n",
    "est4 = LinearDML(model_y=best_model_y, model_t=best_model_t, discrete_treatment=True, linear_first_stages=False, random_state=42)\n",
    "est4.fit(Y_train, T_train, X=X_train, W=None)\n",
    "te_pred4 = est4.effect(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(Y_test, te_pred, label='LinearDML with auto first-stage models')\n",
    "# plt.scatter(Y_test, te_pred1, label='LinearDML with Random Forest first-stage models')\n",
    "# plt.scatter(Y_test, te_pred2, label='LinearDML with Linear first-stage models')\n",
    "# plt.scatter(Y_test, te_pred3, label='LinearDML with Gradient Boosting first-stage models')\n",
    "# plt.scatter(Y_test, te_pred4, label='LinearDML with Neural Networks first-stage models')\n",
    "te_true = Y_test[T_test == True].mean() - Y_test[T_test == False].mean()\n",
    "plt.scatter(Y_test[T_test == False], np.zeros_like(Y_test[T_test == False]) - te_true, color='red', label='True Effect')\n",
    "plt.ylabel('Treatment Effect')\n",
    "plt.xlabel('x')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearDML with auto first-stage models': 1.3957488005531276,\n",
       " 'LinearDML with Random Forest first-stage models': 1.3147824035317122,\n",
       " 'LinearDML with Linear first-stage models': 1.3622069797461647,\n",
       " 'LinearDML with Gradient Boosting first-stage models': 1.5981875810583352,\n",
       " 'LinearDML with Neural Networks first-stage models': 1.4460264382685382}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score={}\n",
    "score[\"LinearDML with auto first-stage models\"] = est.score(Y_test, T_test, X_test)\n",
    "score[\"LinearDML with Random Forest first-stage models\"] = est1.score(Y_test, T_test, X_test)\n",
    "score[\"LinearDML with Linear first-stage models\"] = est2.score(Y_test, T_test, X_test)\n",
    "score[\"LinearDML with Gradient Boosting first-stage models\"] = est3.score(Y_test, T_test, X_test)\n",
    "score[\"LinearDML with Neural Networks first-stage models\"] = est4.score(Y_test, T_test, X_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model selected by score:  LinearDML with Random Forest first-stage models\n"
     ]
    }
   ],
   "source": [
    "print(\"best model selected by score: \",min(score,key=lambda x: score.get(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearDML with auto first-stage models': 8.13159312074027,\n",
       " 'LinearDML with Random Forest first-stage models': 9.230302488828961,\n",
       " 'LinearDML with Linear first-stage models': 8.27422578568749,\n",
       " 'LinearDML with Gradient Boosting first-stage models': 8.687611337099003,\n",
       " 'LinearDML with Neural Networks first-stage models': 8.935276689936945}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_te = {}\n",
    "mse_te['LinearDML with auto first-stage models'] = np.mean((Y_test - te_pred)**2)\n",
    "mse_te['LinearDML with Random Forest first-stage models'] = np.mean((Y_test - te_pred1)**2)\n",
    "mse_te['LinearDML with Linear first-stage models'] = np.mean((Y_test - te_pred2)**2)\n",
    "mse_te['LinearDML with Gradient Boosting first-stage models'] = np.mean((Y_test - te_pred3)**2)\n",
    "mse_te['LinearDML with Neural Networks first-stage models'] = np.mean((Y_test - te_pred4)**2)\n",
    "mse_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model selected by MSE of TE:  LinearDML with auto first-stage models\n"
     ]
    }
   ],
   "source": [
    "print(\"best model selected by MSE of TE: \", min(mse_te, key=lambda x: mse_te.get(x)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
