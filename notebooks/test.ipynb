{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/anthonycampbell/Documents')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.orf import DMLOrthoForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name  age           city\n",
      "0   John   25       New York\n",
      "1  Emily   30  San Francisco\n",
      "2  David   20        Seattle\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a list of dictionaries\n",
    "data = [\n",
    "    {'name': 'John', 'age': 25, 'city': 'New York'},\n",
    "    {'name': 'Emily', 'age': 30, 'city': 'San Francisco'},\n",
    "    {'name': 'David', 'age': 20, 'city': 'Seattle'}\n",
    "]\n",
    "\n",
    "# create a dataframe from the list of dictionaries\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# print the dataframe\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../datasets/IHDP/ihdp_splits_10iters_10folds.npz', allow_pickle=True)\n",
    "# n_iters = options.iters if options.iters > 0 else splits.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from sklearn.linear_model import (Lasso, LassoCV, ElasticNetCV, LogisticRegression,\n",
    "                                  LogisticRegressionCV,LinearRegression,\n",
    "                                  MultiTaskElasticNet,MultiTaskElasticNetCV)\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor,RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "models_and_parameters = [    ('elastic', ElasticNetCV(), {}),    \n",
    "('forest', RandomForestRegressor(),        {'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20],\n",
    "        'min_samples_leaf': [0.01, 0.02, 0.03, 0.04, 0.05, 1, 2, 3, 4, 5, 6, 7, 8, 9]}),\n",
    "    ('gbf', GradientBoostingRegressor(),\n",
    "        {\"n_estimators\": [100, 300, 500, 700, 1000],\n",
    "        \"max_depth\": [2, 4, 6, 8, 10],\n",
    "        \"min_samples_split\": [5, 10, 15, 20],\n",
    "        \"learning_rate\": [0.001, 0.01, 0.1, 0.2, 1]}),\n",
    "    ('nnet', MLPRegressor(),\n",
    "        {'hidden_layer_sizes': [4, 8, 16, 32, 64, 128],\n",
    "        'learning_rate_init': [0.0001, 0.001],\n",
    "        'batch_size': [32, 64, 128, 250]})\n",
    "]\n",
    "models_dict = {name: (model, params) for name, model, params in models_and_parameters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {name: {'model': model, 'parameters': params} for name, model, params in models_and_parameters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elastic': {'model': ElasticNetCV(), 'parameters': {}},\n",
       " 'forest': {'model': RandomForestRegressor(),\n",
       "  'parameters': {'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20],\n",
       "   'min_samples_leaf': [0.01,\n",
       "    0.02,\n",
       "    0.03,\n",
       "    0.04,\n",
       "    0.05,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9]}},\n",
       " 'gbf': {'model': GradientBoostingRegressor(),\n",
       "  'parameters': {'n_estimators': [100, 300, 500, 700, 1000],\n",
       "   'max_depth': [2, 4, 6, 8, 10],\n",
       "   'min_samples_split': [5, 10, 15, 20],\n",
       "   'learning_rate': [0.001, 0.01, 0.1, 0.2, 1]}},\n",
       " 'nnet': {'model': MLPRegressor(),\n",
       "  'parameters': {'hidden_layer_sizes': [4, 8, 16, 32, 64, 128],\n",
       "   'learning_rate_init': [0.0001, 0.001],\n",
       "   'batch_size': [32, 64, 128, 250]}}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
